# QuestionForge - Scope Analysis & Extension Opportunities

**Date:** November 4, 2025
**Version:** 2.0
**Purpose:** Define current scope, limitations, and extension possibilities

---

## ğŸ¯ Current Scope (v2.0)

### âœ… What QuestionForge IS Designed For

**1. Educational Questions (Primary Use Case)**
- Assessment questions with learning objectives
- Question formats: single_word, short_question, predict_output, debug_fix, scenario_task, fill_in_blank, explain_concept, compare_contrast, rewrite
- Metadata: Bloom's level, difficulty, style, keywords, prerequisites
- Purpose: Evaluate student understanding

**2. Python Programming Focus**
- Python-specific terminology (PEP 8, LEGB, GIL, MRO)
- Python best practices validation
- Python code examples and syntax
- Python development workflows

**3. Educational Quality Assessment**
- Adult learning principles (andragogy)
- Pedagogical soundness (Bloom's taxonomy)
- People-first inclusivity
- Practical application
- Construct validity (measures what it claims)
- Cognitive depth (Six Facets)

### âŒ What QuestionForge is NOT Currently Designed For

**1. General Content Quality Assessment**
- âŒ Tutorial/guide quality
- âŒ Documentation quality
- âŒ Blog post/article quality
- âŒ Code comment quality
- âŒ README file quality

**2. Answer Validation**
- âŒ Does not score answer quality
- âŒ Does not validate correct answers
- âŒ Does not check distractor quality (multiple choice options)
- âŒ Does not grade rubrics

**3. Non-Question Content**
- âŒ Not for code quality analysis (use linters instead)
- âŒ Not for prose/writing quality (use writing tools)
- âŒ Not for video/multimedia content

---

## ğŸ”¬ Deep Dive: Can It Be Extended?

### Question 1: Can QuestionForge Assess General Content Quality?

**Short Answer:** ğŸŸ¡ **PARTIALLY - Requires Significant Adaptation**

#### What Would Transfer Well:

**1. Adult Learning Principles (90% applicable)**
```
âœ… Real-world context â†’ Applies to tutorials
âœ… Practical examples â†’ Applies to docs
âœ… Concrete variables â†’ Applies to code examples
âœ… Avoiding abstract â†’ Applies to explanations
```

**2. People-First Principles (100% applicable)**
```
âœ… Diverse names â†’ Applies to all content
âœ… Inclusive language â†’ Applies to all content
âœ… Accessible phrasing â†’ Applies to all content
âœ… Growth mindset â†’ Applies to all content
```

**3. Practical Application (80% applicable)**
```
âœ… Industry relevance â†’ Applies to tutorials
âœ… Tool awareness â†’ Applies to guides
âœ… Job-relevant â†’ Applies to training content
âš ï¸ Best practices â†’ Depends on content type
```

**4. RAG Optimization (100% applicable)**
```
âœ… Keyword richness â†’ Applies to all searchable content
âœ… Semantic search â†’ Applies to all content
âœ… Relationship mapping â†’ Applies to docs
```

**5. Cognitive Depth (70% applicable)**
```
âœ… Explanation facet â†’ Applies to tutorials
âœ… Application facet â†’ Applies to examples
âœ… Perspective facet â†’ Applies to comparisons
âš ï¸ Self-knowledge â†’ Less relevant for reference docs
```

#### What Would NOT Transfer:

**1. Bloom's Taxonomy (10% applicable)**
```
âŒ Designed for learning objectives
âŒ Questions assess understanding
âŒ Tutorials teach, not assess
âš ï¸ Could adapt: "What level of understanding does this enable?"
```

**2. Construct Validity (20% applicable)**
```
âŒ "Does this question measure what it claims?"
âŒ Not applicable to explanatory content
âš ï¸ Could adapt: "Does this content achieve its stated purpose?"
```

#### Architecture Changes Needed:

**Current Architecture (Question-Specific):**
```python
@dataclass
class Question:
    question: str          # The question text
    style: str            # Question format
    bloom_level: str      # Cognitive level being assessed
    answer_type: str      # Expected answer format
```

**Proposed Generic Architecture:**
```python
@dataclass
class Content:
    content: str          # The main content
    content_type: str     # tutorial, explanation, example, reference
    purpose: str          # What this content aims to achieve
    target_audience: str  # beginner, intermediate, advanced

    # Reuse existing fields
    keywords: List[str]
    prerequisites: List[str]
```

**Effort Required:** ğŸ”´ **HIGH** (4-6 weeks)
- New parser for different content types
- New transformers for content-specific improvements
- Adapt 7 criteria scoring (some need redesign)
- New validation thresholds
- New test suite

**Verdict:**
âœ… **POSSIBLE** but requires fork/extension: "ContentForge"
âš ï¸ **NOT RECOMMENDED** for v2.x - keep focus on questions

---

### Question 2: Can QuestionForge Support Other Programming Languages?

**Short Answer:** ğŸŸ¢ **YES - Relatively Easy Extension**

#### Current Python-Specific Elements:

**1. Config Templates (config.yaml):**
```yaml
# PYTHON-SPECIFIC:
realistic_variables:
  strings: [name, username, email, ...]  # Language-agnostic âœ…
  numbers: [price, quantity, score, ...]  # Language-agnostic âœ…

# Would need language variants for:
# - Naming conventions (snake_case vs camelCase vs PascalCase)
# - Standard library references
# - Idioms and patterns
```

**2. Analyzer Checks (analyzer.py):**
```python
# Lines 233-238: Python-specific
if "python 3.1" in text_lower or "python 3" in text_lower:
    score += 0.3
if "python 2" in text_lower:
    score -= 1.0

# Lines 139-143: Python jargon
jargon_terms = ["legb", "gil", "monkey patch", "mro"]
```

**3. Practical Scoring (analyzer.py):**
```python
# Lines 196-200: Python standards
industry_terms = [
    "pep 8", "python 3", "best practice", ...
]
```

#### How to Extend to Other Languages:

**Option A: Language Field (RECOMMENDED)**

```python
# 1. Add language to Question dataclass
@dataclass
class Question:
    # ... existing fields ...
    language: str = "python"  # NEW: python, javascript, java, etc.

# 2. Update config.yaml
languages:
  python:
    naming_convention: "snake_case"
    version_current: "3.10+"
    version_legacy: "2.x"
    standards: ["PEP 8"]
    jargon: ["legb", "gil", "mro"]

  javascript:
    naming_convention: "camelCase"
    version_current: "ES6+"
    version_legacy: "ES5"
    standards: ["ESLint", "Airbnb Style"]
    jargon: ["hoisting", "closure", "event loop"]

  java:
    naming_convention: "camelCase"
    version_current: "Java 17+"
    version_legacy: "Java 8"
    standards: ["Oracle Conventions"]
    jargon: ["jvm", "garbage collection", "interface"]

# 3. Update analyzer to use language config
def _score_practical_application(self, q: Question) -> float:
    lang_config = self.config['languages'].get(q.language, {})
    standards = lang_config.get('standards', [])
    current_version = lang_config.get('version_current')
    legacy_version = lang_config.get('version_legacy')

    # Check for current standards
    if any(std.lower() in text_lower for std in standards):
        score += 0.7

    # Check for legacy version (penalty)
    if legacy_version and legacy_version.lower() in text_lower:
        score -= 1.0
```

**Effort Required:** ğŸŸ¡ **MEDIUM** (1-2 weeks per language)
- Add language field to dataclass
- Create language configs in YAML
- Update analyzer to use language configs
- Create language-specific templates
- Test with sample questions

**Languages Easy to Add:**
- âœ… JavaScript (similar ecosystem)
- âœ… Java (well-established standards)
- âœ… C# (clear conventions)
- âœ… Go (opinionated style)
- âœ… Rust (strong conventions)

**Languages Harder to Add:**
- âš ï¸ C/C++ (multiple styles, less standardized)
- âš ï¸ PHP (fragmented ecosystem)
- âš ï¸ Ruby (convention-heavy but varies)

---

## ğŸ¯ Scope Expansion Roadmap

### v2.1 - Multi-Language Support (4-6 weeks)

**Goal:** Support Python + 2 other languages

**Tasks:**
1. âœ… Add `language` field to Question dataclass
2. âœ… Create language configs (Python, JavaScript, Java)
3. âœ… Update analyzer to use language-specific patterns
4. âœ… Create language-specific templates
5. âœ… Test with 30 questions per language
6. âœ… Document language extension guide

**Benefit:** 3x addressable market (Python â†’ Python + JS + Java)

---

### v2.5 - Content Quality Scoring (8-12 weeks)

**Goal:** Fork QuestionForge â†’ Create "ContentForge"

**New Supported Types:**
- Tutorials (step-by-step guides)
- Explanations (conceptual articles)
- Code Examples (standalone snippets)
- Reference Docs (API documentation)

**Architecture:**
```python
# New base class
class ContentItem:
    content: str
    content_type: str
    purpose: str

# Subclasses
class Question(ContentItem):
    # Existing Question fields

class Tutorial(ContentItem):
    steps: List[str]
    learning_outcomes: List[str]

class Explanation(ContentItem):
    concept: str
    depth_level: str
```

**Adapted Criteria:**
1. âœ… Adult Learning â†’ "Practical Context"
2. âœ… People-First â†’ Unchanged
3. ğŸ”„ Bloom's â†’ "Learning Enablement" (what can learner do after?)
4. âœ… Practical â†’ Unchanged
5. âœ… RAG â†’ Unchanged
6. ğŸ”„ Construct Validity â†’ "Purpose Alignment"
7. âœ… Cognitive Depth â†’ Unchanged

**Benefit:** Assess entire curriculum, not just questions

---

### v3.0 - Psychometric Analysis (Requires Student Data)

**Goal:** Add statistical validation

**New Capabilities:**
- Item difficulty (p-value) from student performance
- Item discrimination (point-biserial correlation)
- Reliability (Cronbach's alpha)
- Factor analysis (validate 7 criteria independence)

**Requirements:**
- âŒ Need real student response data
- âŒ Need sample size: 100+ students per question
- âŒ Need LMS integration or data pipeline

**Benefit:** NCCA-level psychometric validation

---

## ğŸ“Š Comparison Matrix

| Feature | v2.0 (Current) | v2.1 (Multi-Lang) | v2.5 (ContentForge) | v3.0 (Psychometric) |
|---------|---------------|-------------------|---------------------|---------------------|
| **Question Quality** | âœ… Python | âœ… 3+ languages | âœ… All languages | âœ… + Statistics |
| **Tutorial Quality** | âŒ | âŒ | âœ… | âœ… |
| **Code Example Quality** | âŒ | âŒ | âœ… | âœ… |
| **Docs Quality** | âŒ | âŒ | âœ… | âœ… |
| **Language Support** | Python only | Python + 2 | Any | Any |
| **Student Data** | âŒ | âŒ | âŒ | âœ… Required |
| **Standards** | Academic + Industry | Same | Same | + Psychometric |
| **Use Case** | Question banks | Question banks | Full curriculum | Certification exams |

---

## ğŸ¯ Current Scope Summary

### âœ… QuestionForge v2.0 IS:
- **Specialized** - Question quality assessment
- **Python-focused** - But extensible to other languages (v2.1)
- **Educational** - Learning objectives and pedagogy
- **Standards-based** - Academic + Industry validation
- **Automated** - Batch processing, systematic improvement

### âŒ QuestionForge v2.0 IS NOT:
- **General content tool** - Not for tutorials, docs, articles (yet)
- **Code quality tool** - Not a linter or static analyzer
- **Answer validator** - Doesn't check correctness
- **Multi-language** - Python-only (until v2.1)
- **Statistical** - No psychometric analysis (until v3.0)

---

## ğŸ’¡ Recommendations

### For Your Use Case:

**If you need:** Question quality for Python curriculum
â†’ âœ… **Use v2.0 NOW** - Perfect fit

**If you need:** Question quality for JS/Java curriculum
â†’ â³ **Wait for v2.1** (4-6 weeks) OR **Adapt config yourself** (2 weeks)

**If you need:** Tutorial/content quality assessment
â†’ â³ **Wait for ContentForge v2.5** (3-4 months) OR **Hire custom development**

**If you need:** Psychometric validation
â†’ â³ **Wait for v3.0** (6+ months) + **Collect student data**

### Quick Extension Guide:

**To add JavaScript support (DIY - 1 week):**
1. Add JavaScript language config to `config.yaml`
2. Update 3 checks in `analyzer.py` (lines 196-238)
3. Test with 10 sample JS questions
4. Document in README

**To assess tutorial quality (Advanced - 4 weeks):**
1. Create `Tutorial` dataclass
2. Create `TutorialAnalyzer` class
3. Adapt 5/7 criteria (drop Bloom's, adapt construct validity)
4. Create tutorial-specific transformers
5. Build separate CLI command or fork codebase

---

## ğŸ“ Support & Custom Development

If you need:
- âœ… Multi-language support (v2.1 features early)
- âœ… Content quality assessment (ContentForge)
- âœ… Custom criteria or adaptations
- âœ… Integration with your LMS/CMS
- âœ… Psychometric consulting

**Contact:** Quest & Crossfire Arsenal

---

**Last Updated:** November 4, 2025
**Next Review:** After v2.1 release
